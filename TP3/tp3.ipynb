{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Travail Pratique 3</h1>\n",
    "\n",
    "<p>Nom de l'équipe sur Kaggle : Hello world!<p>\n",
    "<p>Membres de l'équipe:</p>\n",
    "<ul>\n",
    "    <li>Jacob Massih, 2050874</li>\n",
    "    <li>Ali Ameziane, 2007033</li>\n",
    "    <li>John Maliha, 1984959</li>\n",
    "</ul>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Justification des choix de principaux librairies</h2>\n",
    "\n",
    "La bibliothèque Pandas est utilisée pour la manipulation de données, notamment pour lire les données à partir de fichiers ou de bases de données et pour effectuer des opérations de transformation sur les données.\n",
    "\n",
    "La bibliothèque Scikit-learn (sklearn) est utilisée pour le prétraitement des données, la création de jeux de données d'entraînement et de tests, l'entraînement du modèle de classification, l'évaluation de la performance du modèle avec les matrices de confusion et les rapports de classification, ainsi que pour la normalisation des données en utilisant la StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Importations des données</h2>\n",
    "\n",
    "Nous importons les deux fichiers de données, celui contenant les données pour l'entraînement, et ceux pour les tests à l'aide de la librairie pandas, sous forme de DataFrame afin de faciliter leur manipulation. Nous observons d'ailleurs la présence d'une colonne contenant les index dans les fichiers, d'où la précision du second paramètre dans chacun des appels de read_csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train.csv', index_col=0)\n",
    "test_data = pd.read_csv('data/test.csv', index_col=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Prétraitement des données</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première ligne de code définit la variable 'X' en utilisant la méthode Pandas drop pour supprimer deux colonnes de l'ensemble de données d'entraînement : status et url. \n",
    "\n",
    "La deuxième ligne définit la variable 'y' comme la colonne status de l'ensemble de données d'entraînement.\n",
    "\n",
    "La troisième ligne de code définit la variable X_testing en supprimant la colonne url de l'ensemble de données de test.\n",
    "\n",
    "La quatrième ligne de code utilise la méthode train_test_split de la bibliothèque Scikit-learn (sklearn) pour diviser l'ensemble de données d'entraînement en deux jeux de données : un ensemble de données d'entraînement (X_train, y_train) et un ensemble de données de test (X_test, y_test). Le paramètre random_state est utilisé pour garantir la reproductibilité des résultats, et l'argument test_size est utilisé pour spécifier la taille de l'ensemble de données de test (0,0001 de l'ensemble de données d'entraînement).\n",
    "\n",
    "La sélection de la valeur 0.0001 pour la taille de l'ensemble de données de test n'a pas été effectuée de manière arbitraire. En effet, plusieurs tests ont été réalisés pour déterminer la taille optimale de l'ensemble de données de test. Initialement, une taille de 20% a été utilisée, suivie par une taille de 10%, puis de 5%. Une fois que le modèle a été finalisé, il a été décidé de réduire la taille de l'ensemble de données de test à tendre vers 0%. Cette approche a été adoptée afin de permettre au modèle de prendre en compte un plus grand nombre de données pour générer des prédictions plus précises et ainsi obtenir un meilleur score lors de la compétition sur Kaggle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop([ 'status', 'url'], axis=1)\n",
    "y = train_data['status']\n",
    "X_testing = test_data.drop(['url'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=42, test_size=0.00000000000001) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, nous utilisons le StandardScaler dans le but de normaliser les différentes colonnes nécessaire pour construire le modèle. Cela permet éventuellement d'avoir un meilleur modèle puisque qu'ils possèderont une échelle similaire suite à la standarisation.\n",
    "\n",
    "Dans la seconde ligne, le StandardScaler trouve l'échelle optimale selon les données de X_train et l'applique la transformation.\n",
    "\n",
    "Dans la troisième ligne, on applique uniquement la tranformation selon l'échelle optimale trouvé à l'étape précédente.\n",
    "\n",
    "Dans la dernière ligne, nous appliquons la même logique que la ligne précédente pour les données de testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "X_testing = sc.transform(X_testing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Gradient Boosting Classifier</h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de sélectionner le Gradient Boosting Classifier comme modèle pour notre problème de classification, nous avons mené une évaluation comparative en utilisant plusieurs algorithmes d'apprentissage automatique couramment utilisés, en gardant à l'esprit que notre jeu de donnée était relativement petit (inférieur à 10 000).\n",
    "\n",
    "La régression logistique nous a fourni une précision de 64,912%, ce qui n'a pas répondu à nos exigences en matière de performances. Le modèle de réseau de neurones (MLP Classifier) a montré une précision d'environ 86%, ce qui était une amélioration significative par rapport à la régression logistique, mais pas suffisant pour répondre à nos exigences de précision. Le modèle de forêt aléatoire (Random Forest Classifier) a montré une précision de 96,842%, qui était très prometteur, mais nous avons continué notre exploration pour déterminer s'il existait une méthode encore plus performante pour notre ensemble de données.\n",
    "\n",
    "Finalement, après avoir testé le Gradient Boosting Classifier, nous avons atteint une précision maximale de 96,929%.\n",
    "\n",
    "Ci-dessous une description détaillé de la manière dont nous avons utilisé Gradient Boosting Classifier ainsi que la justification des choix des différents paramètres.\n",
    "\n",
    "La première ligne de code crée une instance de la classe GradientBoostingClassifier avec l'argument n_estimators défini à 3000. Cette valeur définit le nombre d'arbres de décision qui seront créés et agrégés pour former le modèle final. Une valeur plus élevée de n_estimators peut potentiellement améliorer la précision du modèle, mais peut également augmenter le temps de traitement nécessaire pour l'apprentissage, donc nous avons decide de rester sur 30000 estimateurs.\n",
    "\n",
    "La deuxième ligne de code utilise la méthode \"fit\" pour entraîner le modèle sur l'ensemble de données d'entraînement 'X_train' et 'y_train'.\n",
    "\n",
    "La troisième ligne de code utilise la méthode \"predict\" pour générer des prédictions à partir de l'ensemble de données de test 'X_test' en utilisant le modèle entraîné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(n_estimators=4000)\n",
    "model.fit(X_train, y_train)\n",
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Métriques d'analyse des résultats du modèle</h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons la méthode 'classification_report' de sklearn dans le but de monitorer la métrique de précision de notre modèle actuel. Cette méthode utilise comme paramètre 'y_test' et 'prediction' afin d'effectuer cette analyse. Nous utilisons également la méthode 'confusion_matrix' de sklearn avec les même deux paramètres dans le but d'observer une matrice de confusion selon notre modèle actuel. De plus, nous affichons en ordre décroissant les métriques selon leur niveau d'importance dans notre modèle en accédant à l'attribut 'feature_importances' de notre objet 'model'. Nous utilisons ces outils dans le but de tenter d'interpréter l'effet des différentes changements effecutés sur notre modèle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    phishing       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n",
      "[[1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "google_index               0.557127\n",
       "page_rank                  0.127459\n",
       "nb_hyperlinks              0.076383\n",
       "nb_www                     0.042866\n",
       "web_traffic                0.030656\n",
       "                             ...   \n",
       "nb_dollar                  0.000000\n",
       "nb_external_redirection    0.000000\n",
       "ratio_intErrors            0.000000\n",
       "sfh                        0.000000\n",
       "ratio_nullHyperlinks       0.000000\n",
       "Length: 87, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(y_test,prediction))\n",
    "print(confusion_matrix(y_test, prediction))\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "\n",
    "feature_scores = pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "feature_scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Prédiction pour les cas de tests</h2>\n",
    "\n",
    "Dans la première ligne, nous utilisons la méthode 'predict' avec paramètre 'X_testing' dans le but de prédire la valeur de status selon notre modèle. Par la suite, nous ajoutons les prédicitons dans une colonne status dans le dataframe 'test_data'. Nous exportons par la suite les colonnes 'url' et 'status' dans un nouvel DataFrame nommé 'url_and_status'. Finalement, nous exportons ce DataFrame dans un fichier nommé 'output.csv' qui sera utilisé pour la soumissions sur Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['status'] = model.predict(X_testing)\n",
    "url_and_status = test_data[['url','status']]\n",
    "url_and_status.to_csv('data/output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
